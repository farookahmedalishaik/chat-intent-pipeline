Requirements

util

config

preprocess








Stage 1: Data Preparation (Run Once)
This stage prepares all the necessary data from your source of truth.

ingest_clean.py

load_to_mysql.py

prepare_data.py

push_data_artifacts.py

Stage 2: Model Training & Validation (Iterative Loop)
This is the loop where you develop your model. You repeat these steps until you are satisfied with the model's performance on the validation set.

finetune_bert_simpler.py

This trains the model and saves the best version locally in your artifacts folder.

validation_dashboard.py

Run this immediately after training. It will use the local model and local validation data to show you the performance metrics and confusion matrix.

➡️ At this point, you analyze the results in the dashboard. If you're not satisfied, you can adjust hyperparameters in config.py and run Stage 2 again.

Stage 3: Final Testing & Deployment (Run Once Finalized)
Once you are happy with your model from Stage 2, you proceed with these final steps to get test metrics and deploy the model to the cloud.

export_bert_metrics.py

This runs your finalized model against the unseen test set.

push_evaluation_artifacts.py

This uploads the final test results (metrics, predictions) to your data repository.

push_model.py

This uploads your finalized and validated model to the model repository.

Stage 4: Analysis & Application
After your final model and its test results are in the cloud, you can run these scripts.

error_analysis_clean.py (To analyze errors on the test set)

analysis/export_top_confusions.py (To dig deeper into test set confusion)

app.py (To run the final user-facing application)



